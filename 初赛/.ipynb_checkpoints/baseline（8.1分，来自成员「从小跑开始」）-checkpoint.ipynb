{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#import xgboost as xgb\n",
    "#import catboost as cb\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./train_s1/exam_score.csv')\n",
    "df_test = pd.read_csv('./test_s1/submission_s1.csv')\n",
    "df_test.rename(columns={'pred':'score'},inplace = True)\n",
    "course_class = pd.read_csv('./train_s1/course.csv')\n",
    "student = pd.read_csv('./train_s1/student.csv')\n",
    "all_know = pd.read_csv('./train_s1/all_knowledge.csv')\n",
    "df_all = df_train.append(df_test)\n",
    "df_all = df_all.merge(course_class, on='course', how='left')\n",
    "df_all = df_all.merge(student, on='student_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = df_train.groupby(by=['student_id','course'], as_index=False)['score'].agg({'mean_score':np.mean, 'median_score':np.median, 'std_score':np.std,'max_score':np.max,'min_score':np.min})\n",
    "tmp2 = df_train.groupby(by=['student_id'], as_index=False)['score'].agg({'s_mean_score':np.mean, 's_median_score':np.median, 's_std_score':np.std,'s_max_score':np.max,'min_score':np.min})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all=df_all.merge(tmp1, on=['student_id','course'], how='left')\n",
    "df_all=df_all.merge(tmp2, on=['student_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "course1_exam = pd.read_csv('./train_s1/course1_exams.csv')\n",
    "course2_exam = pd.read_csv('./train_s1/course2_exams.csv')\n",
    "course3_exam = pd.read_csv('./train_s1/course3_exams.csv')\n",
    "course4_exam = pd.read_csv('./train_s1/course4_exams.csv')\n",
    "course5_exam = pd.read_csv('./train_s1/course5_exams.csv')\n",
    "course6_exam = pd.read_csv('./train_s1/course6_exams.csv')\n",
    "course7_exam = pd.read_csv('./train_s1/course7_exams.csv')\n",
    "course8_exam = pd.read_csv('./train_s1/course8_exams.csv')\n",
    "#col_c1 = [i for i in course1_exam.columns if i not in ['course','exam_id']]\n",
    "tmp4=1\n",
    "for i in [course1_exam,course2_exam,course3_exam,course4_exam,course5_exam,course6_exam,course7_exam,course8_exam]:\n",
    "    name = i\n",
    "    col_c1 = [i for i in name.columns if i not in ['course','exam_id']]\n",
    "    name['course'] ='course'+str(tmp4)\n",
    "    tmp2 =np.array(all_know.loc[all_know['course'] == ('course'+str(tmp4)),:]['complexity'])\n",
    "    tmp = name[col_c1]\n",
    "    tmp3 =np.dot(tmp.values,tmp2)\n",
    "    name['hard'] = tmp3\n",
    "    name['hard_inverse'] = name['hard'].apply(lambda x:1/(x+1e-10))\n",
    "    tmp4 = tmp4+1\n",
    "\n",
    "course_exam = course1_exam.append(course2_exam)\n",
    "course_exam = course_exam.append(course3_exam)\n",
    "course_exam = course_exam.append(course4_exam)\n",
    "course_exam = course_exam.append(course5_exam)\n",
    "course_exam = course_exam.append(course6_exam)\n",
    "course_exam = course_exam.append(course7_exam)\n",
    "course_exam = course_exam.append(course8_exam)\n",
    "course_exam.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_course_exam = course_exam[['course','exam_id','hard','hard_inverse']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73500, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all=df_all.merge(sub_course_exam, on=['exam_id','course'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73500, 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将课程对应的知识点的对应的段落和知识点加入特征\n",
    "#df_all=df_all.merge(all_know,on=['course'],how='left')\n",
    "df_all.shape\n",
    "#特征选择\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['student_id', 'course', 'exam_id', 'course_class', 'gender', 'mean_score', 'median_score', 'std_score', 'max_score', 'min_score_x', 's_mean_score', 's_median_score', 's_std_score', 's_max_score', 'min_score_y', 'hard', 'hard_inverse']\n",
      "(65500, 17)\n",
      "Index(['student_id', 'course', 'exam_id', 'course_class', 'gender',\n",
      "       'mean_score', 'median_score', 'std_score', 'max_score', 'min_score_x',\n",
      "       's_mean_score', 's_median_score', 's_std_score', 's_max_score',\n",
      "       'min_score_y', 'hard', 'hard_inverse'],\n",
      "      dtype='object')\n",
      "features sorted by their rank:\n",
      "RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False),\n",
      "  n_features_to_select=2, step=1, verbose=0)\n",
      "[(1, 'hard_inverse'), (1, 'mean_score'), (2, 'course_class'), (3, 'course'), (4, 'hard'), (5, 's_mean_score'), (6, 'max_score'), (7, 'std_score'), (8, 'min_score_x'), (9, 'median_score'), (10, 's_median_score'), (11, 's_max_score'), (12, 'exam_id'), (13, 'gender'), (14, 's_std_score'), (15, 'min_score_y'), (16, 'student_id')]\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "for i in ['course','course_class','exam_id','student_id']:\n",
    "    lbl = LabelEncoder()\n",
    "    #all_data[i+\"_count\"] = all_data.groupby([i])[i].transform('count')\n",
    "    #all_data[i+\"_rank\"] = all_data[i+\"_count\"].rank(method='min')\n",
    "    df_all[i] = lbl.fit_transform(df_all[i].astype(str))\n",
    "#将数据集保存\n",
    "df_all.to_csv('df_all.csv')\n",
    "#添加特征工程\n",
    "df_train = df_all[:65500]\n",
    "lr=LinearRegression()\n",
    "rfe=RFE(lr,n_features_to_select=2)#选择剔除1个\n",
    "target=[i for i in df_train.columns if i not in ['score']]\n",
    "print(target)\n",
    "X=df_train[target]\n",
    "print(X.shape)\n",
    "Y=df_train['score']\n",
    "names=X.columns\n",
    "print(names)\n",
    "rfe.fit(X,Y)\n",
    "print(\"features sorted by their rank:\")\n",
    "print(rfe)\n",
    "futures=sorted(zip(map(lambda x:round(x,4), rfe.ranking_),names))#特征选择出的特征\n",
    "print(futures)\n",
    "print(len(futures))\n",
    "#将训练集和测试集的特征换成新的特征\n",
    "df_test = df_all[65500:].reset_index(drop=True)\n",
    "X.drop(['hard_inverse','mean_score'],axis=1)\n",
    "df_test=df_test.drop(['hard_inverse','mean_score'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8c86f435d5df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m65500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m65500\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_all' is not defined"
     ]
    }
   ],
   "source": [
    "df_train = df_all[:65500]\n",
    "df_test = df_all[65500:].reset_index(drop=True)\n",
    "col = [i for i in df_all.columns if i not in ['score']]\n",
    "X_train = df_train[col]\n",
    "y = df_train['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds.\n",
      "[10]\ttrain's rmse: 9.44372\ttrain's l2: 89.1839\tval's rmse: 9.46607\tval's l2: 89.6064\n",
      "[20]\ttrain's rmse: 8.94165\ttrain's l2: 79.9531\tval's rmse: 8.96684\tval's l2: 80.4043\n",
      "[30]\ttrain's rmse: 8.495\ttrain's l2: 72.165\tval's rmse: 8.52292\tval's l2: 72.6402\n",
      "[40]\ttrain's rmse: 8.09333\ttrain's l2: 65.5021\tval's rmse: 8.12432\tval's l2: 66.0047\n",
      "[50]\ttrain's rmse: 7.75715\ttrain's l2: 60.1733\tval's rmse: 7.79053\tval's l2: 60.6924\n",
      "[60]\ttrain's rmse: 7.44394\ttrain's l2: 55.4122\tval's rmse: 7.47948\tval's l2: 55.9426\n",
      "[70]\ttrain's rmse: 7.18905\ttrain's l2: 51.6824\tval's rmse: 7.22716\tval's l2: 52.2318\n",
      "[80]\ttrain's rmse: 6.96126\ttrain's l2: 48.4592\tval's rmse: 7.00162\tval's l2: 49.0227\n",
      "[90]\ttrain's rmse: 6.75986\ttrain's l2: 45.6956\tval's rmse: 6.80263\tval's l2: 46.2758\n",
      "[100]\ttrain's rmse: 6.59477\ttrain's l2: 43.4909\tval's rmse: 6.63859\tval's l2: 44.0708\n",
      "[110]\ttrain's rmse: 6.45224\ttrain's l2: 41.6314\tval's rmse: 6.49786\tval's l2: 42.2222\n",
      "[120]\ttrain's rmse: 6.32632\ttrain's l2: 40.0223\tval's rmse: 6.37329\tval's l2: 40.6188\n",
      "[130]\ttrain's rmse: 6.22148\ttrain's l2: 38.7068\tval's rmse: 6.27094\tval's l2: 39.3247\n",
      "[140]\ttrain's rmse: 6.13465\ttrain's l2: 37.6339\tval's rmse: 6.18648\tval's l2: 38.2725\n",
      "[150]\ttrain's rmse: 6.05849\ttrain's l2: 36.7054\tval's rmse: 6.11218\tval's l2: 37.3587\n",
      "[160]\ttrain's rmse: 5.99273\ttrain's l2: 35.9128\tval's rmse: 6.0489\tval's l2: 36.5892\n",
      "[170]\ttrain's rmse: 5.93495\ttrain's l2: 35.2236\tval's rmse: 5.99331\tval's l2: 35.9197\n",
      "[180]\ttrain's rmse: 5.88817\ttrain's l2: 34.6706\tval's rmse: 5.94977\tval's l2: 35.3998\n",
      "[190]\ttrain's rmse: 5.8464\ttrain's l2: 34.1803\tval's rmse: 5.90971\tval's l2: 34.9247\n",
      "[200]\ttrain's rmse: 5.81311\ttrain's l2: 33.7922\tval's rmse: 5.87867\tval's l2: 34.5588\n",
      "[210]\ttrain's rmse: 5.78379\ttrain's l2: 33.4522\tval's rmse: 5.85208\tval's l2: 34.2468\n",
      "[220]\ttrain's rmse: 5.75822\ttrain's l2: 33.1571\tval's rmse: 5.82978\tval's l2: 33.9864\n",
      "[230]\ttrain's rmse: 5.7341\ttrain's l2: 32.8799\tval's rmse: 5.80874\tval's l2: 33.7414\n",
      "[240]\ttrain's rmse: 5.71324\ttrain's l2: 32.6411\tval's rmse: 5.79033\tval's l2: 33.528\n",
      "[250]\ttrain's rmse: 5.69463\ttrain's l2: 32.4288\tval's rmse: 5.77363\tval's l2: 33.3348\n",
      "[260]\ttrain's rmse: 5.68016\ttrain's l2: 32.2642\tval's rmse: 5.76188\tval's l2: 33.1992\n",
      "[270]\ttrain's rmse: 5.66411\ttrain's l2: 32.0821\tval's rmse: 5.74896\tval's l2: 33.0506\n",
      "[280]\ttrain's rmse: 5.65166\ttrain's l2: 31.9413\tval's rmse: 5.73837\tval's l2: 32.9289\n",
      "[290]\ttrain's rmse: 5.64013\ttrain's l2: 31.8111\tval's rmse: 5.72941\tval's l2: 32.8261\n",
      "[300]\ttrain's rmse: 5.63018\ttrain's l2: 31.699\tval's rmse: 5.7228\tval's l2: 32.7505\n",
      "[310]\ttrain's rmse: 5.62043\ttrain's l2: 31.5892\tval's rmse: 5.71597\tval's l2: 32.6723\n",
      "[320]\ttrain's rmse: 5.61039\ttrain's l2: 31.4764\tval's rmse: 5.709\tval's l2: 32.5927\n",
      "[330]\ttrain's rmse: 5.60124\ttrain's l2: 31.3739\tval's rmse: 5.70391\tval's l2: 32.5346\n",
      "[340]\ttrain's rmse: 5.59319\ttrain's l2: 31.2838\tval's rmse: 5.69921\tval's l2: 32.481\n",
      "[350]\ttrain's rmse: 5.58635\ttrain's l2: 31.2073\tval's rmse: 5.69478\tval's l2: 32.4306\n",
      "[360]\ttrain's rmse: 5.58025\ttrain's l2: 31.1392\tval's rmse: 5.69157\tval's l2: 32.394\n",
      "[370]\ttrain's rmse: 5.57358\ttrain's l2: 31.0648\tval's rmse: 5.68738\tval's l2: 32.3462\n",
      "[380]\ttrain's rmse: 5.5675\ttrain's l2: 30.997\tval's rmse: 5.68509\tval's l2: 32.3202\n",
      "[390]\ttrain's rmse: 5.56292\ttrain's l2: 30.946\tval's rmse: 5.68362\tval's l2: 32.3036\n",
      "[400]\ttrain's rmse: 5.55618\ttrain's l2: 30.8711\tval's rmse: 5.68005\tval's l2: 32.263\n",
      "[410]\ttrain's rmse: 5.55131\ttrain's l2: 30.817\tval's rmse: 5.67754\tval's l2: 32.2345\n",
      "[420]\ttrain's rmse: 5.54576\ttrain's l2: 30.7554\tval's rmse: 5.67468\tval's l2: 32.202\n",
      "[430]\ttrain's rmse: 5.54107\ttrain's l2: 30.7035\tval's rmse: 5.67196\tval's l2: 32.1712\n",
      "[440]\ttrain's rmse: 5.53576\ttrain's l2: 30.6447\tval's rmse: 5.66936\tval's l2: 32.1416\n",
      "[450]\ttrain's rmse: 5.53036\ttrain's l2: 30.5849\tval's rmse: 5.66663\tval's l2: 32.1107\n",
      "[460]\ttrain's rmse: 5.52535\ttrain's l2: 30.5295\tval's rmse: 5.66515\tval's l2: 32.0939\n",
      "[470]\ttrain's rmse: 5.51984\ttrain's l2: 30.4686\tval's rmse: 5.66387\tval's l2: 32.0794\n",
      "[480]\ttrain's rmse: 5.51553\ttrain's l2: 30.4211\tval's rmse: 5.66231\tval's l2: 32.0618\n",
      "[490]\ttrain's rmse: 5.50998\ttrain's l2: 30.3599\tval's rmse: 5.66028\tval's l2: 32.0387\n",
      "[500]\ttrain's rmse: 5.50606\ttrain's l2: 30.3167\tval's rmse: 5.65793\tval's l2: 32.0122\n",
      "[510]\ttrain's rmse: 5.50016\ttrain's l2: 30.2518\tval's rmse: 5.65528\tval's l2: 31.9822\n",
      "[520]\ttrain's rmse: 5.49567\ttrain's l2: 30.2023\tval's rmse: 5.65457\tval's l2: 31.9742\n",
      "[530]\ttrain's rmse: 5.49048\ttrain's l2: 30.1454\tval's rmse: 5.65181\tval's l2: 31.9429\n",
      "[540]\ttrain's rmse: 5.48644\ttrain's l2: 30.101\tval's rmse: 5.65013\tval's l2: 31.9239\n",
      "[550]\ttrain's rmse: 5.48273\ttrain's l2: 30.0603\tval's rmse: 5.64946\tval's l2: 31.9164\n",
      "[560]\ttrain's rmse: 5.47813\ttrain's l2: 30.0099\tval's rmse: 5.64695\tval's l2: 31.888\n",
      "[570]\ttrain's rmse: 5.47628\ttrain's l2: 29.9896\tval's rmse: 5.64782\tval's l2: 31.8979\n",
      "[580]\ttrain's rmse: 5.47323\ttrain's l2: 29.9562\tval's rmse: 5.64788\tval's l2: 31.8985\n",
      "Early stopping, best iteration is:\n",
      "[562]\ttrain's rmse: 5.47765\ttrain's l2: 30.0047\tval's rmse: 5.64648\tval's l2: 31.8827\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[10]\ttrain's rmse: 9.44419\ttrain's l2: 89.1927\tval's rmse: 9.45539\tval's l2: 89.4043\n",
      "[20]\ttrain's rmse: 8.94093\ttrain's l2: 79.9403\tval's rmse: 8.95442\tval's l2: 80.1816\n",
      "[30]\ttrain's rmse: 8.49512\ttrain's l2: 72.1671\tval's rmse: 8.51165\tval's l2: 72.4482\n",
      "[40]\ttrain's rmse: 8.09171\ttrain's l2: 65.4758\tval's rmse: 8.11184\tval's l2: 65.8019\n",
      "[50]\ttrain's rmse: 7.75586\ttrain's l2: 60.1533\tval's rmse: 7.77921\tval's l2: 60.5162\n",
      "[60]\ttrain's rmse: 7.441\ttrain's l2: 55.3684\tval's rmse: 7.46943\tval's l2: 55.7924\n",
      "[70]\ttrain's rmse: 7.18409\ttrain's l2: 51.6111\tval's rmse: 7.2169\tval's l2: 52.0836\n",
      "[80]\ttrain's rmse: 6.95412\ttrain's l2: 48.3597\tval's rmse: 6.99199\tval's l2: 48.888\n",
      "[90]\ttrain's rmse: 6.75193\ttrain's l2: 45.5886\tval's rmse: 6.79671\tval's l2: 46.1953\n",
      "[100]\ttrain's rmse: 6.58725\ttrain's l2: 43.3919\tval's rmse: 6.63728\tval's l2: 44.0535\n",
      "[110]\ttrain's rmse: 6.44409\ttrain's l2: 41.5263\tval's rmse: 6.49971\tval's l2: 42.2462\n",
      "[120]\ttrain's rmse: 6.31736\ttrain's l2: 39.909\tval's rmse: 6.3788\tval's l2: 40.6891\n",
      "[130]\ttrain's rmse: 6.21154\ttrain's l2: 38.5833\tval's rmse: 6.27975\tval's l2: 39.4353\n",
      "[140]\ttrain's rmse: 6.12447\ttrain's l2: 37.5091\tval's rmse: 6.19744\tval's l2: 38.4082\n",
      "[150]\ttrain's rmse: 6.04771\ttrain's l2: 36.5748\tval's rmse: 6.12628\tval's l2: 37.5313\n",
      "[160]\ttrain's rmse: 5.98189\ttrain's l2: 35.783\tval's rmse: 6.06573\tval's l2: 36.7931\n",
      "[170]\ttrain's rmse: 5.92411\ttrain's l2: 35.095\tval's rmse: 6.01376\tval's l2: 36.1654\n",
      "[180]\ttrain's rmse: 5.87751\ttrain's l2: 34.5452\tval's rmse: 5.97238\tval's l2: 35.6693\n",
      "[190]\ttrain's rmse: 5.8344\ttrain's l2: 34.0402\tval's rmse: 5.9346\tval's l2: 35.2194\n",
      "[200]\ttrain's rmse: 5.80021\ttrain's l2: 33.6425\tval's rmse: 5.90637\tval's l2: 34.8852\n",
      "[210]\ttrain's rmse: 5.77106\ttrain's l2: 33.3051\tval's rmse: 5.88184\tval's l2: 34.5961\n",
      "[220]\ttrain's rmse: 5.74546\ttrain's l2: 33.0103\tval's rmse: 5.86054\tval's l2: 34.3459\n",
      "[230]\ttrain's rmse: 5.72136\ttrain's l2: 32.7339\tval's rmse: 5.84105\tval's l2: 34.1179\n",
      "[240]\ttrain's rmse: 5.69959\ttrain's l2: 32.4854\tval's rmse: 5.82473\tval's l2: 33.9274\n",
      "[250]\ttrain's rmse: 5.68112\ttrain's l2: 32.2751\tval's rmse: 5.81052\tval's l2: 33.7621\n",
      "[260]\ttrain's rmse: 5.66644\ttrain's l2: 32.1085\tval's rmse: 5.80034\tval's l2: 33.6439\n",
      "[270]\ttrain's rmse: 5.65154\ttrain's l2: 31.9399\tval's rmse: 5.79075\tval's l2: 33.5328\n",
      "[280]\ttrain's rmse: 5.63905\ttrain's l2: 31.7989\tval's rmse: 5.78315\tval's l2: 33.4449\n",
      "[290]\ttrain's rmse: 5.62684\ttrain's l2: 31.6613\tval's rmse: 5.77556\tval's l2: 33.3571\n",
      "[300]\ttrain's rmse: 5.61629\ttrain's l2: 31.5427\tval's rmse: 5.77041\tval's l2: 33.2976\n",
      "[310]\ttrain's rmse: 5.60618\ttrain's l2: 31.4292\tval's rmse: 5.76502\tval's l2: 33.2354\n",
      "[320]\ttrain's rmse: 5.5956\ttrain's l2: 31.3108\tval's rmse: 5.7596\tval's l2: 33.173\n",
      "[330]\ttrain's rmse: 5.5871\ttrain's l2: 31.2157\tval's rmse: 5.75642\tval's l2: 33.1364\n",
      "[340]\ttrain's rmse: 5.57927\ttrain's l2: 31.1283\tval's rmse: 5.75312\tval's l2: 33.0984\n",
      "[350]\ttrain's rmse: 5.57269\ttrain's l2: 31.0549\tval's rmse: 5.74968\tval's l2: 33.0588\n",
      "[360]\ttrain's rmse: 5.56648\ttrain's l2: 30.9857\tval's rmse: 5.74687\tval's l2: 33.0265\n",
      "[370]\ttrain's rmse: 5.56012\ttrain's l2: 30.9149\tval's rmse: 5.74318\tval's l2: 32.9841\n",
      "[380]\ttrain's rmse: 5.55437\ttrain's l2: 30.851\tval's rmse: 5.74144\tval's l2: 32.9642\n",
      "[390]\ttrain's rmse: 5.54906\ttrain's l2: 30.792\tval's rmse: 5.73942\tval's l2: 32.9409\n",
      "[400]\ttrain's rmse: 5.54305\ttrain's l2: 30.7254\tval's rmse: 5.73639\tval's l2: 32.9061\n",
      "[410]\ttrain's rmse: 5.53888\ttrain's l2: 30.6791\tval's rmse: 5.73627\tval's l2: 32.9048\n",
      "[420]\ttrain's rmse: 5.53277\ttrain's l2: 30.6116\tval's rmse: 5.73277\tval's l2: 32.8646\n",
      "[430]\ttrain's rmse: 5.52755\ttrain's l2: 30.5538\tval's rmse: 5.73083\tval's l2: 32.8425\n",
      "[440]\ttrain's rmse: 5.52228\ttrain's l2: 30.4956\tval's rmse: 5.72943\tval's l2: 32.8264\n",
      "[450]\ttrain's rmse: 5.5171\ttrain's l2: 30.4384\tval's rmse: 5.72937\tval's l2: 32.8257\n",
      "Early stopping, best iteration is:\n",
      "[437]\ttrain's rmse: 5.52314\ttrain's l2: 30.505\tval's rmse: 5.72888\tval's l2: 32.8201\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[10]\ttrain's rmse: 9.44696\ttrain's l2: 89.2451\tval's rmse: 9.44204\tval's l2: 89.1522\n",
      "[20]\ttrain's rmse: 8.94638\ttrain's l2: 80.0377\tval's rmse: 8.94218\tval's l2: 79.9626\n",
      "[30]\ttrain's rmse: 8.50006\ttrain's l2: 72.251\tval's rmse: 8.49649\tval's l2: 72.1904\n",
      "[40]\ttrain's rmse: 8.09708\ttrain's l2: 65.5627\tval's rmse: 8.09314\tval's l2: 65.4989\n",
      "[50]\ttrain's rmse: 7.76142\ttrain's l2: 60.2396\tval's rmse: 7.75906\tval's l2: 60.203\n",
      "[60]\ttrain's rmse: 7.44985\ttrain's l2: 55.5002\tval's rmse: 7.44817\tval's l2: 55.4752\n",
      "[70]\ttrain's rmse: 7.1933\ttrain's l2: 51.7436\tval's rmse: 7.19398\tval's l2: 51.7533\n",
      "[80]\ttrain's rmse: 6.9654\ttrain's l2: 48.5168\tval's rmse: 6.96815\tval's l2: 48.5551\n",
      "[90]\ttrain's rmse: 6.76566\ttrain's l2: 45.7741\tval's rmse: 6.76908\tval's l2: 45.8205\n",
      "[100]\ttrain's rmse: 6.6011\ttrain's l2: 43.5745\tval's rmse: 6.60616\tval's l2: 43.6413\n",
      "[110]\ttrain's rmse: 6.45907\ttrain's l2: 41.7196\tval's rmse: 6.46713\tval's l2: 41.8238\n",
      "[120]\ttrain's rmse: 6.33198\ttrain's l2: 40.094\tval's rmse: 6.34218\tval's l2: 40.2232\n",
      "[130]\ttrain's rmse: 6.22802\ttrain's l2: 38.7883\tval's rmse: 6.24055\tval's l2: 38.9445\n",
      "[140]\ttrain's rmse: 6.1412\ttrain's l2: 37.7143\tval's rmse: 6.15579\tval's l2: 37.8938\n",
      "[150]\ttrain's rmse: 6.06553\ttrain's l2: 36.7907\tval's rmse: 6.08286\tval's l2: 37.0011\n",
      "[160]\ttrain's rmse: 6.00054\ttrain's l2: 36.0064\tval's rmse: 6.02082\tval's l2: 36.2503\n",
      "[170]\ttrain's rmse: 5.94314\ttrain's l2: 35.3209\tval's rmse: 5.96612\tval's l2: 35.5946\n",
      "[180]\ttrain's rmse: 5.89647\ttrain's l2: 34.7684\tval's rmse: 5.92343\tval's l2: 35.087\n",
      "[190]\ttrain's rmse: 5.85357\ttrain's l2: 34.2643\tval's rmse: 5.88347\tval's l2: 34.6152\n",
      "[200]\ttrain's rmse: 5.8188\ttrain's l2: 33.8584\tval's rmse: 5.85232\tval's l2: 34.2496\n",
      "[210]\ttrain's rmse: 5.78942\ttrain's l2: 33.5174\tval's rmse: 5.82708\tval's l2: 33.9549\n",
      "[220]\ttrain's rmse: 5.76409\ttrain's l2: 33.2247\tval's rmse: 5.80531\tval's l2: 33.7016\n",
      "[230]\ttrain's rmse: 5.74004\ttrain's l2: 32.948\tval's rmse: 5.78423\tval's l2: 33.4573\n",
      "[240]\ttrain's rmse: 5.71861\ttrain's l2: 32.7025\tval's rmse: 5.76547\tval's l2: 33.2407\n",
      "[250]\ttrain's rmse: 5.70037\ttrain's l2: 32.4943\tval's rmse: 5.75084\tval's l2: 33.0722\n",
      "[260]\ttrain's rmse: 5.68543\ttrain's l2: 32.3241\tval's rmse: 5.73987\tval's l2: 32.9461\n",
      "[270]\ttrain's rmse: 5.67025\ttrain's l2: 32.1518\tval's rmse: 5.72784\tval's l2: 32.8082\n",
      "[280]\ttrain's rmse: 5.65779\ttrain's l2: 32.0106\tval's rmse: 5.71834\tval's l2: 32.6994\n",
      "[290]\ttrain's rmse: 5.64663\ttrain's l2: 31.8845\tval's rmse: 5.71002\tval's l2: 32.6044\n",
      "[300]\ttrain's rmse: 5.63628\ttrain's l2: 31.7677\tval's rmse: 5.70327\tval's l2: 32.5273\n",
      "[310]\ttrain's rmse: 5.62655\ttrain's l2: 31.6581\tval's rmse: 5.6966\tval's l2: 32.4512\n",
      "[320]\ttrain's rmse: 5.61766\ttrain's l2: 31.5581\tval's rmse: 5.69122\tval's l2: 32.39\n",
      "[330]\ttrain's rmse: 5.60887\ttrain's l2: 31.4594\tval's rmse: 5.68564\tval's l2: 32.3265\n",
      "[340]\ttrain's rmse: 5.59981\ttrain's l2: 31.3579\tval's rmse: 5.68045\tval's l2: 32.2675\n",
      "[350]\ttrain's rmse: 5.59206\ttrain's l2: 31.2712\tval's rmse: 5.676\tval's l2: 32.217\n",
      "[360]\ttrain's rmse: 5.58558\ttrain's l2: 31.1987\tval's rmse: 5.67242\tval's l2: 32.1763\n",
      "[370]\ttrain's rmse: 5.57826\ttrain's l2: 31.117\tval's rmse: 5.66809\tval's l2: 32.1273\n",
      "[380]\ttrain's rmse: 5.57246\ttrain's l2: 31.0523\tval's rmse: 5.666\tval's l2: 32.1035\n",
      "[390]\ttrain's rmse: 5.56661\ttrain's l2: 30.9871\tval's rmse: 5.66375\tval's l2: 32.078\n",
      "[400]\ttrain's rmse: 5.56054\ttrain's l2: 30.9196\tval's rmse: 5.66099\tval's l2: 32.0468\n",
      "[410]\ttrain's rmse: 5.55549\ttrain's l2: 30.8634\tval's rmse: 5.66012\tval's l2: 32.037\n",
      "[420]\ttrain's rmse: 5.55018\ttrain's l2: 30.8045\tval's rmse: 5.65858\tval's l2: 32.0195\n",
      "[430]\ttrain's rmse: 5.54553\ttrain's l2: 30.7529\tval's rmse: 5.65747\tval's l2: 32.0069\n",
      "[440]\ttrain's rmse: 5.5399\ttrain's l2: 30.6905\tval's rmse: 5.65569\tval's l2: 31.9869\n",
      "[450]\ttrain's rmse: 5.53527\ttrain's l2: 30.6392\tval's rmse: 5.65381\tval's l2: 31.9656\n",
      "[460]\ttrain's rmse: 5.5297\ttrain's l2: 30.5775\tval's rmse: 5.65197\tval's l2: 31.9447\n",
      "[470]\ttrain's rmse: 5.52478\ttrain's l2: 30.5232\tval's rmse: 5.65054\tval's l2: 31.9286\n",
      "[480]\ttrain's rmse: 5.52072\ttrain's l2: 30.4784\tval's rmse: 5.64975\tval's l2: 31.9197\n",
      "[490]\ttrain's rmse: 5.51464\ttrain's l2: 30.4112\tval's rmse: 5.64651\tval's l2: 31.8831\n",
      "[500]\ttrain's rmse: 5.5116\ttrain's l2: 30.3777\tval's rmse: 5.647\tval's l2: 31.8886\n",
      "[510]\ttrain's rmse: 5.50576\ttrain's l2: 30.3134\tval's rmse: 5.64611\tval's l2: 31.8785\n",
      "[520]\ttrain's rmse: 5.50145\ttrain's l2: 30.266\tval's rmse: 5.64437\tval's l2: 31.859\n",
      "[530]\ttrain's rmse: 5.49729\ttrain's l2: 30.2202\tval's rmse: 5.64343\tval's l2: 31.8483\n",
      "[540]\ttrain's rmse: 5.49333\ttrain's l2: 30.1766\tval's rmse: 5.64348\tval's l2: 31.8488\n",
      "Early stopping, best iteration is:\n",
      "[528]\ttrain's rmse: 5.49775\ttrain's l2: 30.2253\tval's rmse: 5.64271\tval's l2: 31.8402\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[10]\ttrain's rmse: 9.44846\ttrain's l2: 89.2734\tval's rmse: 9.44298\tval's l2: 89.1699\n",
      "[20]\ttrain's rmse: 8.94589\ttrain's l2: 80.0289\tval's rmse: 8.94545\tval's l2: 80.0211\n",
      "[30]\ttrain's rmse: 8.50038\ttrain's l2: 72.2564\tval's rmse: 8.50498\tval's l2: 72.3347\n",
      "[40]\ttrain's rmse: 8.09639\ttrain's l2: 65.5515\tval's rmse: 8.10575\tval's l2: 65.7032\n",
      "[50]\ttrain's rmse: 7.7613\ttrain's l2: 60.2378\tval's rmse: 7.7754\tval's l2: 60.4568\n",
      "[60]\ttrain's rmse: 7.44654\ttrain's l2: 55.451\tval's rmse: 7.46458\tval's l2: 55.72\n",
      "[70]\ttrain's rmse: 7.18969\ttrain's l2: 51.6916\tval's rmse: 7.21302\tval's l2: 52.0276\n",
      "[80]\ttrain's rmse: 6.96081\ttrain's l2: 48.4528\tval's rmse: 6.98831\tval's l2: 48.8364\n",
      "[90]\ttrain's rmse: 6.75851\ttrain's l2: 45.6774\tval's rmse: 6.79167\tval's l2: 46.1268\n",
      "[100]\ttrain's rmse: 6.59305\ttrain's l2: 43.4683\tval's rmse: 6.63054\tval's l2: 43.9641\n",
      "[110]\ttrain's rmse: 6.44985\ttrain's l2: 41.6006\tval's rmse: 6.49181\tval's l2: 42.1435\n",
      "[120]\ttrain's rmse: 6.32217\ttrain's l2: 39.9698\tval's rmse: 6.36804\tval's l2: 40.552\n",
      "[130]\ttrain's rmse: 6.2185\ttrain's l2: 38.6697\tval's rmse: 6.26862\tval's l2: 39.2956\n",
      "[140]\ttrain's rmse: 6.13063\ttrain's l2: 37.5846\tval's rmse: 6.18506\tval's l2: 38.2549\n",
      "[150]\ttrain's rmse: 6.0543\ttrain's l2: 36.6546\tval's rmse: 6.11346\tval's l2: 37.3744\n",
      "[160]\ttrain's rmse: 5.98845\ttrain's l2: 35.8615\tval's rmse: 6.05204\tval's l2: 36.6272\n",
      "[170]\ttrain's rmse: 5.93061\ttrain's l2: 35.1721\tval's rmse: 5.99898\tval's l2: 35.9877\n",
      "[180]\ttrain's rmse: 5.88387\ttrain's l2: 34.62\tval's rmse: 5.95646\tval's l2: 35.4794\n",
      "[190]\ttrain's rmse: 5.84129\ttrain's l2: 34.1207\tval's rmse: 5.91782\tval's l2: 35.0206\n",
      "[200]\ttrain's rmse: 5.80732\ttrain's l2: 33.7249\tval's rmse: 5.88858\tval's l2: 34.6754\n",
      "[210]\ttrain's rmse: 5.77791\ttrain's l2: 33.3843\tval's rmse: 5.86339\tval's l2: 34.3793\n",
      "[220]\ttrain's rmse: 5.75288\ttrain's l2: 33.0957\tval's rmse: 5.84229\tval's l2: 34.1323\n",
      "[230]\ttrain's rmse: 5.72894\ttrain's l2: 32.8208\tval's rmse: 5.8223\tval's l2: 33.8991\n",
      "[240]\ttrain's rmse: 5.7083\ttrain's l2: 32.5847\tval's rmse: 5.80486\tval's l2: 33.6964\n",
      "[250]\ttrain's rmse: 5.68994\ttrain's l2: 32.3754\tval's rmse: 5.78997\tval's l2: 33.5237\n",
      "[260]\ttrain's rmse: 5.675\ttrain's l2: 32.2056\tval's rmse: 5.77795\tval's l2: 33.3847\n",
      "[270]\ttrain's rmse: 5.6589\ttrain's l2: 32.0231\tval's rmse: 5.76562\tval's l2: 33.2423\n",
      "[280]\ttrain's rmse: 5.64648\ttrain's l2: 31.8828\tval's rmse: 5.75711\tval's l2: 33.1443\n",
      "[290]\ttrain's rmse: 5.63508\ttrain's l2: 31.7541\tval's rmse: 5.74955\tval's l2: 33.0574\n",
      "[300]\ttrain's rmse: 5.62498\ttrain's l2: 31.6405\tval's rmse: 5.74303\tval's l2: 32.9824\n",
      "[310]\ttrain's rmse: 5.61591\ttrain's l2: 31.5385\tval's rmse: 5.73685\tval's l2: 32.9114\n",
      "[320]\ttrain's rmse: 5.60572\ttrain's l2: 31.4241\tval's rmse: 5.7308\tval's l2: 32.8421\n",
      "[330]\ttrain's rmse: 5.59708\ttrain's l2: 31.3273\tval's rmse: 5.72493\tval's l2: 32.7748\n",
      "[340]\ttrain's rmse: 5.58865\ttrain's l2: 31.233\tval's rmse: 5.72038\tval's l2: 32.7228\n",
      "[350]\ttrain's rmse: 5.58122\ttrain's l2: 31.15\tval's rmse: 5.71575\tval's l2: 32.6698\n",
      "[360]\ttrain's rmse: 5.57504\ttrain's l2: 31.0811\tval's rmse: 5.713\tval's l2: 32.6384\n",
      "[370]\ttrain's rmse: 5.56845\ttrain's l2: 31.0076\tval's rmse: 5.7109\tval's l2: 32.6144\n",
      "[380]\ttrain's rmse: 5.56278\ttrain's l2: 30.9445\tval's rmse: 5.70805\tval's l2: 32.5819\n",
      "[390]\ttrain's rmse: 5.55803\ttrain's l2: 30.8917\tval's rmse: 5.70632\tval's l2: 32.5621\n",
      "[400]\ttrain's rmse: 5.5517\ttrain's l2: 30.8214\tval's rmse: 5.70396\tval's l2: 32.5351\n",
      "[410]\ttrain's rmse: 5.54694\ttrain's l2: 30.7685\tval's rmse: 5.70231\tval's l2: 32.5163\n",
      "[420]\ttrain's rmse: 5.54158\ttrain's l2: 30.7092\tval's rmse: 5.69995\tval's l2: 32.4895\n",
      "[430]\ttrain's rmse: 5.53721\ttrain's l2: 30.6607\tval's rmse: 5.69824\tval's l2: 32.47\n",
      "[440]\ttrain's rmse: 5.53167\ttrain's l2: 30.5993\tval's rmse: 5.69533\tval's l2: 32.4367\n",
      "[450]\ttrain's rmse: 5.52754\ttrain's l2: 30.5536\tval's rmse: 5.69458\tval's l2: 32.4282\n",
      "[460]\ttrain's rmse: 5.5232\ttrain's l2: 30.5058\tval's rmse: 5.69238\tval's l2: 32.4031\n",
      "[470]\ttrain's rmse: 5.51793\ttrain's l2: 30.4475\tval's rmse: 5.69163\tval's l2: 32.3947\n",
      "[480]\ttrain's rmse: 5.51413\ttrain's l2: 30.4056\tval's rmse: 5.69044\tval's l2: 32.3811\n",
      "[490]\ttrain's rmse: 5.50874\ttrain's l2: 30.3462\tval's rmse: 5.68838\tval's l2: 32.3576\n",
      "[500]\ttrain's rmse: 5.50379\ttrain's l2: 30.2917\tval's rmse: 5.68527\tval's l2: 32.3223\n",
      "[510]\ttrain's rmse: 5.49864\ttrain's l2: 30.235\tval's rmse: 5.68284\tval's l2: 32.2947\n",
      "[520]\ttrain's rmse: 5.49402\ttrain's l2: 30.1842\tval's rmse: 5.68171\tval's l2: 32.2818\n",
      "[530]\ttrain's rmse: 5.49008\ttrain's l2: 30.141\tval's rmse: 5.68061\tval's l2: 32.2693\n",
      "[540]\ttrain's rmse: 5.48584\ttrain's l2: 30.0945\tval's rmse: 5.67897\tval's l2: 32.2507\n",
      "[550]\ttrain's rmse: 5.4829\ttrain's l2: 30.0622\tval's rmse: 5.67973\tval's l2: 32.2593\n",
      "[560]\ttrain's rmse: 5.47996\ttrain's l2: 30.03\tval's rmse: 5.67955\tval's l2: 32.2573\n",
      "[570]\ttrain's rmse: 5.47588\ttrain's l2: 29.9852\tval's rmse: 5.67896\tval's l2: 32.2506\n",
      "[580]\ttrain's rmse: 5.47271\ttrain's l2: 29.9506\tval's rmse: 5.67998\tval's l2: 32.2622\n",
      "Early stopping, best iteration is:\n",
      "[567]\ttrain's rmse: 5.47686\ttrain's l2: 29.996\tval's rmse: 5.67824\tval's l2: 32.2425\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[10]\ttrain's rmse: 9.44952\ttrain's l2: 89.2934\tval's rmse: 9.44051\tval's l2: 89.1233\n",
      "[20]\ttrain's rmse: 8.94679\ttrain's l2: 80.045\tval's rmse: 8.94233\tval's l2: 79.9653\n",
      "[30]\ttrain's rmse: 8.49979\ttrain's l2: 72.2465\tval's rmse: 8.50003\tval's l2: 72.2506\n",
      "[40]\ttrain's rmse: 8.09688\ttrain's l2: 65.5595\tval's rmse: 8.102\tval's l2: 65.6425\n",
      "[50]\ttrain's rmse: 7.75988\ttrain's l2: 60.2158\tval's rmse: 7.7701\tval's l2: 60.3745\n",
      "[60]\ttrain's rmse: 7.44471\ttrain's l2: 55.4237\tval's rmse: 7.46012\tval's l2: 55.6534\n",
      "[70]\ttrain's rmse: 7.18765\ttrain's l2: 51.6623\tval's rmse: 7.20741\tval's l2: 51.9467\n",
      "[80]\ttrain's rmse: 6.95895\ttrain's l2: 48.427\tval's rmse: 6.98393\tval's l2: 48.7752\n",
      "[90]\ttrain's rmse: 6.75722\ttrain's l2: 45.66\tval's rmse: 6.78635\tval's l2: 46.0545\n",
      "[100]\ttrain's rmse: 6.59296\ttrain's l2: 43.4671\tval's rmse: 6.6264\tval's l2: 43.9092\n",
      "[110]\ttrain's rmse: 6.45038\ttrain's l2: 41.6074\tval's rmse: 6.48853\tval's l2: 42.101\n",
      "[120]\ttrain's rmse: 6.32386\ttrain's l2: 39.9912\tval's rmse: 6.36686\tval's l2: 40.5369\n",
      "[130]\ttrain's rmse: 6.21854\ttrain's l2: 38.6702\tval's rmse: 6.26642\tval's l2: 39.268\n",
      "[140]\ttrain's rmse: 6.12954\ttrain's l2: 37.5713\tval's rmse: 6.18349\tval's l2: 38.2356\n",
      "[150]\ttrain's rmse: 6.05376\ttrain's l2: 36.648\tval's rmse: 6.11166\tval's l2: 37.3524\n",
      "[160]\ttrain's rmse: 5.98804\ttrain's l2: 35.8566\tval's rmse: 6.05051\tval's l2: 36.6087\n",
      "[170]\ttrain's rmse: 5.93071\ttrain's l2: 35.1733\tval's rmse: 5.9976\tval's l2: 35.9712\n",
      "[180]\ttrain's rmse: 5.88454\ttrain's l2: 34.6278\tval's rmse: 5.95548\tval's l2: 35.4677\n",
      "[190]\ttrain's rmse: 5.84233\ttrain's l2: 34.1328\tval's rmse: 5.91682\tval's l2: 35.0088\n",
      "[200]\ttrain's rmse: 5.80866\ttrain's l2: 33.7405\tval's rmse: 5.88731\tval's l2: 34.6605\n",
      "[210]\ttrain's rmse: 5.77945\ttrain's l2: 33.402\tval's rmse: 5.86186\tval's l2: 34.3614\n",
      "[220]\ttrain's rmse: 5.75423\ttrain's l2: 33.1111\tval's rmse: 5.83983\tval's l2: 34.1036\n",
      "[230]\ttrain's rmse: 5.72981\ttrain's l2: 32.8307\tval's rmse: 5.81973\tval's l2: 33.8693\n",
      "[240]\ttrain's rmse: 5.70812\ttrain's l2: 32.5826\tval's rmse: 5.80216\tval's l2: 33.6651\n",
      "[250]\ttrain's rmse: 5.68922\ttrain's l2: 32.3672\tval's rmse: 5.78713\tval's l2: 33.4909\n",
      "[260]\ttrain's rmse: 5.6742\ttrain's l2: 32.1966\tval's rmse: 5.7756\tval's l2: 33.3576\n",
      "[270]\ttrain's rmse: 5.65843\ttrain's l2: 32.0178\tval's rmse: 5.76386\tval's l2: 33.2221\n",
      "[280]\ttrain's rmse: 5.64571\ttrain's l2: 31.874\tval's rmse: 5.75519\tval's l2: 33.1222\n",
      "[290]\ttrain's rmse: 5.63394\ttrain's l2: 31.7413\tval's rmse: 5.74732\tval's l2: 33.0317\n",
      "[300]\ttrain's rmse: 5.62359\ttrain's l2: 31.6248\tval's rmse: 5.74063\tval's l2: 32.9548\n",
      "[310]\ttrain's rmse: 5.61362\ttrain's l2: 31.5128\tval's rmse: 5.73502\tval's l2: 32.8904\n",
      "[320]\ttrain's rmse: 5.60388\ttrain's l2: 31.4035\tval's rmse: 5.72793\tval's l2: 32.8092\n",
      "[330]\ttrain's rmse: 5.59563\ttrain's l2: 31.311\tval's rmse: 5.72373\tval's l2: 32.761\n",
      "[340]\ttrain's rmse: 5.58795\ttrain's l2: 31.2252\tval's rmse: 5.72019\tval's l2: 32.7206\n",
      "[350]\ttrain's rmse: 5.58015\ttrain's l2: 31.1381\tval's rmse: 5.71659\tval's l2: 32.6794\n",
      "[360]\ttrain's rmse: 5.57382\ttrain's l2: 31.0675\tval's rmse: 5.71412\tval's l2: 32.6511\n",
      "[370]\ttrain's rmse: 5.56675\ttrain's l2: 30.9887\tval's rmse: 5.70963\tval's l2: 32.5999\n",
      "[380]\ttrain's rmse: 5.56063\ttrain's l2: 30.9206\tval's rmse: 5.70643\tval's l2: 32.5634\n",
      "[390]\ttrain's rmse: 5.55532\ttrain's l2: 30.8615\tval's rmse: 5.7058\tval's l2: 32.5561\n",
      "[400]\ttrain's rmse: 5.54902\ttrain's l2: 30.7916\tval's rmse: 5.70228\tval's l2: 32.516\n",
      "[410]\ttrain's rmse: 5.54404\ttrain's l2: 30.7363\tval's rmse: 5.70118\tval's l2: 32.5034\n",
      "[420]\ttrain's rmse: 5.53858\ttrain's l2: 30.6759\tval's rmse: 5.69859\tval's l2: 32.4739\n",
      "[430]\ttrain's rmse: 5.53418\ttrain's l2: 30.6271\tval's rmse: 5.69796\tval's l2: 32.4668\n",
      "[440]\ttrain's rmse: 5.52854\ttrain's l2: 30.5648\tval's rmse: 5.69642\tval's l2: 32.4492\n",
      "[450]\ttrain's rmse: 5.52352\ttrain's l2: 30.5093\tval's rmse: 5.69387\tval's l2: 32.4201\n",
      "[460]\ttrain's rmse: 5.51908\ttrain's l2: 30.4603\tval's rmse: 5.69161\tval's l2: 32.3945\n",
      "[470]\ttrain's rmse: 5.51443\ttrain's l2: 30.409\tval's rmse: 5.69107\tval's l2: 32.3882\n",
      "[480]\ttrain's rmse: 5.50903\ttrain's l2: 30.3494\tval's rmse: 5.68983\tval's l2: 32.3741\n",
      "[490]\ttrain's rmse: 5.50253\ttrain's l2: 30.2779\tval's rmse: 5.68774\tval's l2: 32.3503\n",
      "[500]\ttrain's rmse: 5.49866\ttrain's l2: 30.2353\tval's rmse: 5.68704\tval's l2: 32.3425\n",
      "[510]\ttrain's rmse: 5.49267\ttrain's l2: 30.1695\tval's rmse: 5.68364\tval's l2: 32.3037\n",
      "[520]\ttrain's rmse: 5.48839\ttrain's l2: 30.1224\tval's rmse: 5.68265\tval's l2: 32.2925\n",
      "[530]\ttrain's rmse: 5.48361\ttrain's l2: 30.07\tval's rmse: 5.68064\tval's l2: 32.2697\n",
      "[540]\ttrain's rmse: 5.47878\ttrain's l2: 30.017\tval's rmse: 5.67958\tval's l2: 32.2576\n",
      "[550]\ttrain's rmse: 5.47502\ttrain's l2: 29.9759\tval's rmse: 5.67879\tval's l2: 32.2486\n",
      "[560]\ttrain's rmse: 5.47056\ttrain's l2: 29.927\tval's rmse: 5.67692\tval's l2: 32.2274\n",
      "[570]\ttrain's rmse: 5.46825\ttrain's l2: 29.9017\tval's rmse: 5.67653\tval's l2: 32.223\n",
      "[580]\ttrain's rmse: 5.46564\ttrain's l2: 29.8733\tval's rmse: 5.67704\tval's l2: 32.2287\n",
      "Early stopping, best iteration is:\n",
      "[568]\ttrain's rmse: 5.46869\ttrain's l2: 29.9066\tval's rmse: 5.6762\tval's l2: 32.2192\n",
      "CV score:  5.674503132131901\n"
     ]
    }
   ],
   "source": [
    "test_y = np.zeros(len(df_test))\n",
    "random_seed = 2018\n",
    "cv_model = []\n",
    "cv_score = []\n",
    "skf = StratifiedKFold(n_splits=5, random_state=random_seed, shuffle=True)\n",
    "for index, (train_index, test_index) in enumerate(skf.split(X_train, y)):\n",
    "    #print(index)\n",
    "    train_x, val_x, train_y, val_y = X_train.iloc[train_index], X_train.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'n_estimators': 10000,\n",
    "        #'metric': 'mae',\n",
    "        'learning_rate': 0.01,\n",
    "        'min_child_samples': 46,\n",
    "        'min_child_weight': 0.01,\n",
    "        'subsample_freq': 1,\n",
    "        'num_leaves': 40,\n",
    "        'max_depth': 7,\n",
    "        'subsample': 0.42,\n",
    "        'colsample_bytree': 0.48,\n",
    "        'reg_alpha': 0.15,\n",
    "        'reg_lambda': 5,\n",
    "        'verbose': -1,\n",
    "        'seed': 4590\n",
    "    }\n",
    "    lgb = LGBMRegressor(**lgb_params)\n",
    "\n",
    "\n",
    "    lgb.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "        eval_set=[(train_x, train_y), (val_x, val_y)],\n",
    "        eval_names=['train', 'val'],\n",
    "        eval_metric='rmse',\n",
    "        #eval_metric = evaluate_macroF1_lgb, \n",
    "        early_stopping_rounds=20,\n",
    "        verbose=10,\n",
    "    )\n",
    "    cv_model.append(lgb)\n",
    "    lgb.n_estimators = lgb.best_iteration_\n",
    "    val_y_pred = lgb.predict(val_x)\n",
    "    cv_score.append( np.sqrt(mean_squared_error(val_y,val_y_pred)))\n",
    "    test_y += lgb.predict(df_test[col])/5\n",
    "print(\"CV score: \",np.mean(cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([82.43747043, 77.92102689, 80.10894363, ..., 75.89557761,\n",
       "       71.32959521, 70.3530675 ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test = pd.read_csv('./test_s1/submission_s1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test['pred'] = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>course</th>\n",
       "      <th>exam_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230748</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>82.437470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186851</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>77.921027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>478370</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>80.108944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>692328</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>82.470172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>509128</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>79.586593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>604234</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>96.699663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>992922</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>78.293121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>488841</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>91.024836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>831322</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>81.186599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>940245</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>77.451722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>543834</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>76.384807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>775703</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>94.756143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>967766</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>92.908129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>291359</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>92.858238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>226218</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>93.884250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>108246</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>77.777008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>209909</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>74.823762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>908801</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>83.251154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>227895</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>75.308174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>360479</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>94.408373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>121935</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>82.652410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>516713</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>96.102209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>553260</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>74.811185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>862740</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>85.353740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>282390</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>90.521944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>835300</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>93.665601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>974852</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>77.789713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>401010</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>96.982782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>321731</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>96.702401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>864600</td>\n",
       "      <td>course1</td>\n",
       "      <td>m31I6cTD</td>\n",
       "      <td>68.510709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7970</th>\n",
       "      <td>847249</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>70.994475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7971</th>\n",
       "      <td>128696</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>86.569391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7972</th>\n",
       "      <td>300487</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>88.527571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7973</th>\n",
       "      <td>173400</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>94.394785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7974</th>\n",
       "      <td>798636</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>80.130987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975</th>\n",
       "      <td>201431</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>82.283060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7976</th>\n",
       "      <td>445198</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>74.897982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7977</th>\n",
       "      <td>919396</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>68.533543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7978</th>\n",
       "      <td>906998</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>93.213289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7979</th>\n",
       "      <td>422930</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>90.203383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7980</th>\n",
       "      <td>955606</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>69.428308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7981</th>\n",
       "      <td>979995</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>95.133278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7982</th>\n",
       "      <td>841637</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>93.225879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7983</th>\n",
       "      <td>907040</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>81.879924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7984</th>\n",
       "      <td>691675</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>89.757209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7985</th>\n",
       "      <td>743527</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>78.186602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7986</th>\n",
       "      <td>359824</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>74.844161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7987</th>\n",
       "      <td>536667</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>73.641022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7988</th>\n",
       "      <td>982063</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>83.465557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7989</th>\n",
       "      <td>548231</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>83.263901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7990</th>\n",
       "      <td>577866</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>85.737328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7991</th>\n",
       "      <td>490319</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>88.475199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7992</th>\n",
       "      <td>521121</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>74.083712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>155585</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>93.420471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>758749</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>84.954012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>743747</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>86.348926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>719678</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>82.629052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>227750</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>75.895578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>181683</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>71.329595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>270481</td>\n",
       "      <td>course8</td>\n",
       "      <td>Vdo50vyP</td>\n",
       "      <td>70.353067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      student_id   course   exam_id       pred\n",
       "0         230748  course1  m31I6cTD  82.437470\n",
       "1         186851  course1  m31I6cTD  77.921027\n",
       "2         478370  course1  m31I6cTD  80.108944\n",
       "3         692328  course1  m31I6cTD  82.470172\n",
       "4         509128  course1  m31I6cTD  79.586593\n",
       "5         604234  course1  m31I6cTD  96.699663\n",
       "6         992922  course1  m31I6cTD  78.293121\n",
       "7         488841  course1  m31I6cTD  91.024836\n",
       "8         831322  course1  m31I6cTD  81.186599\n",
       "9         940245  course1  m31I6cTD  77.451722\n",
       "10        543834  course1  m31I6cTD  76.384807\n",
       "11        775703  course1  m31I6cTD  94.756143\n",
       "12        967766  course1  m31I6cTD  92.908129\n",
       "13        291359  course1  m31I6cTD  92.858238\n",
       "14        226218  course1  m31I6cTD  93.884250\n",
       "15        108246  course1  m31I6cTD  77.777008\n",
       "16        209909  course1  m31I6cTD  74.823762\n",
       "17        908801  course1  m31I6cTD  83.251154\n",
       "18        227895  course1  m31I6cTD  75.308174\n",
       "19        360479  course1  m31I6cTD  94.408373\n",
       "20        121935  course1  m31I6cTD  82.652410\n",
       "21        516713  course1  m31I6cTD  96.102209\n",
       "22        553260  course1  m31I6cTD  74.811185\n",
       "23        862740  course1  m31I6cTD  85.353740\n",
       "24        282390  course1  m31I6cTD  90.521944\n",
       "25        835300  course1  m31I6cTD  93.665601\n",
       "26        974852  course1  m31I6cTD  77.789713\n",
       "27        401010  course1  m31I6cTD  96.982782\n",
       "28        321731  course1  m31I6cTD  96.702401\n",
       "29        864600  course1  m31I6cTD  68.510709\n",
       "...          ...      ...       ...        ...\n",
       "7970      847249  course8  Vdo50vyP  70.994475\n",
       "7971      128696  course8  Vdo50vyP  86.569391\n",
       "7972      300487  course8  Vdo50vyP  88.527571\n",
       "7973      173400  course8  Vdo50vyP  94.394785\n",
       "7974      798636  course8  Vdo50vyP  80.130987\n",
       "7975      201431  course8  Vdo50vyP  82.283060\n",
       "7976      445198  course8  Vdo50vyP  74.897982\n",
       "7977      919396  course8  Vdo50vyP  68.533543\n",
       "7978      906998  course8  Vdo50vyP  93.213289\n",
       "7979      422930  course8  Vdo50vyP  90.203383\n",
       "7980      955606  course8  Vdo50vyP  69.428308\n",
       "7981      979995  course8  Vdo50vyP  95.133278\n",
       "7982      841637  course8  Vdo50vyP  93.225879\n",
       "7983      907040  course8  Vdo50vyP  81.879924\n",
       "7984      691675  course8  Vdo50vyP  89.757209\n",
       "7985      743527  course8  Vdo50vyP  78.186602\n",
       "7986      359824  course8  Vdo50vyP  74.844161\n",
       "7987      536667  course8  Vdo50vyP  73.641022\n",
       "7988      982063  course8  Vdo50vyP  83.465557\n",
       "7989      548231  course8  Vdo50vyP  83.263901\n",
       "7990      577866  course8  Vdo50vyP  85.737328\n",
       "7991      490319  course8  Vdo50vyP  88.475199\n",
       "7992      521121  course8  Vdo50vyP  74.083712\n",
       "7993      155585  course8  Vdo50vyP  93.420471\n",
       "7994      758749  course8  Vdo50vyP  84.954012\n",
       "7995      743747  course8  Vdo50vyP  86.348926\n",
       "7996      719678  course8  Vdo50vyP  82.629052\n",
       "7997      227750  course8  Vdo50vyP  75.895578\n",
       "7998      181683  course8  Vdo50vyP  71.329595\n",
       "7999      270481  course8  Vdo50vyP  70.353067\n",
       "\n",
       "[8000 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_test.to_csv('./submisson.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x263656f84e0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAHVCAYAAAAJuQqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWfg/1NQyxwtKJCgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fi = []\n",
    "for i in cv_model:\n",
    "    tmp = {\n",
    "        'name' : col,\n",
    "        'score' : i.feature_importances_\n",
    "    }\n",
    "    fi.append(pd.DataFrame(tmp))\n",
    "    \n",
    "fi = pd.concat(fi)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "fi.groupby(['name'])['score'].agg('mean').sort_values(ascending=False).head(40).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
